# KGå¢å¼ºæ£€ç´¢å®ç°éªŒè¯æ¸…å•

**å®Œæˆæ—¶é—´**: 2025-11-22  
**å®ç°å†…å®¹**: çŸ¥è¯†å›¾è°±å¢å¼ºæ£€ç´¢ç³»ç»Ÿ(è®ºæ–‡æ ¸å¿ƒåˆ›æ–°ç‚¹)

---

## ğŸ“¦ å·²äº¤ä»˜æ–‡ä»¶

### 1. `kg/neo4j_import/import_to_neo4j.py` (360è¡Œ)
**åŠŸèƒ½**: Neo4jçŸ¥è¯†å›¾è°±å¯¼å…¥å™¨

**æ ¸å¿ƒç±»**:
- `Neo4jImporter`: å›¾è°±å¯¼å…¥ä¸»ç±»

**å…³é”®æ–¹æ³•**:
- `_connect()`: å»ºç«‹Neo4jè¿æ¥(è‡ªåŠ¨éªŒè¯)
- `create_constraints()`: åˆ›å»ºå”¯ä¸€æ€§çº¦æŸå’Œç´¢å¼•(concept_id, entity_id, name, lang)
- `import_concepts(concepts, batch_size)`: æ‰¹é‡å¯¼å…¥æ¦‚å¿µèŠ‚ç‚¹(MERGEè¯­ä¹‰,æ”¯æŒæ›´æ–°)
- `import_relations(relations, batch_size)`: æ‰¹é‡å¯¼å…¥å…³ç³»(æŒ‰ç±»å‹åˆ†ç»„)
- `import_from_files(concepts_file, relations_file)`: ä»JSONLæ–‡ä»¶å¯¼å…¥
- `get_statistics()`: è·å–å›¾è°±ç»Ÿè®¡(èŠ‚ç‚¹æ•°ã€å…³ç³»æ•°ã€å…³ç³»ç±»å‹ã€è¯­è¨€åˆ†å¸ƒ)
- `test_query(concept_name)`: æµ‹è¯•æŸ¥è¯¢åŠŸèƒ½

**å…³é”®ç‰¹æ€§**:
- âœ… æ‰¹é‡å¯¼å…¥(batch_size=100,é¿å…å†…å­˜æº¢å‡º)
- âœ… å¢é‡æ›´æ–°(MERGEè¯­ä¹‰,ä¸é‡å¤å¯¼å…¥)
- âœ… çº¦æŸç®¡ç†(è‡ªåŠ¨åˆ›å»ºå”¯ä¸€æ€§çº¦æŸå’Œç´¢å¼•)
- âœ… é”™è¯¯å¤„ç†(å•æ‰¹æ¬¡å¤±è´¥ä¸å½±å“æ•´ä½“)
- âœ… ç»Ÿè®¡åˆ†æ(èŠ‚ç‚¹/å…³ç³»/è¯­è¨€åˆ†å¸ƒ)
- âœ… ä¸Šä¸‹æ–‡ç®¡ç†å™¨(withè¯­å¥è‡ªåŠ¨å…³é—­è¿æ¥)

**CLIæµ‹è¯•**:
```bash
python kg/neo4j_import/import_to_neo4j.py \
  --concepts data/kg/concepts.jsonl \
  --relations data/kg/relations.jsonl \
  --clear \
  --test "grammaire"
```

---

### 2. `retrieval/kg_expansion/entity_linking.py` (320è¡Œ)
**åŠŸèƒ½**: å®ä½“é“¾æ¥å™¨(æŸ¥è¯¢â†’çŸ¥è¯†å›¾è°±)

**æ ¸å¿ƒç±»**:
- `EntityLinker`: å®ä½“é“¾æ¥ä¸»ç±»

**å…³é”®æ–¹æ³•**:
- `link_entities(entities, lang)`: æ‰¹é‡é“¾æ¥å®ä½“åˆ°KGèŠ‚ç‚¹
- `_exact_match(session, entity_name, entity_type, lang)`: ç²¾ç¡®åŒ¹é…(nameå®Œå…¨ç›¸åŒ)
- `_fuzzy_match(session, entity_name, entity_type, lang)`: æ¨¡ç³ŠåŒ¹é…(CONTAINS + ç›¸ä¼¼åº¦è¿‡æ»¤)
- `_string_similarity(s1, s2)`: è®¡ç®—Jaccardç›¸ä¼¼åº¦
- `link_query(query, ner_model, lang)`: å¯¹æŸ¥è¯¢æ–‡æœ¬è¿›è¡Œå®ä½“é“¾æ¥
- `batch_link_queries(queries, ner_model)`: æ‰¹é‡é“¾æ¥

**å…³é”®å‚æ•°**:
- `similarity_threshold`: æ¨¡ç³ŠåŒ¹é…ç›¸ä¼¼åº¦é˜ˆå€¼(é»˜è®¤0.8)

**å…³é”®ç‰¹æ€§**:
- âœ… ä¸¤çº§åŒ¹é…(ç²¾ç¡®â†’æ¨¡ç³Š,ç²¾ç¡®ä¼˜å…ˆ)
- âœ… å¤šè¯­è¨€æ”¯æŒ(langå­—æ®µè¿‡æ»¤)
- âœ… ç±»å‹è¿‡æ»¤(entity_typeçº¦æŸ)
- âœ… ç›¸ä¼¼åº¦è®¡ç®—(Jaccardå­—ç¬¦é›†åˆç›¸ä¼¼åº¦)
- âœ… ç½®ä¿¡åº¦è¯„åˆ†(ç²¾ç¡®åŒ¹é…1.0,æ¨¡ç³ŠåŒ¹é…æŒ‰ç›¸ä¼¼åº¦)
- âœ… NERé›†æˆ(å¯é€‰,æ”¯æŒå…ˆè¯†åˆ«å†é“¾æ¥)

**CLIæµ‹è¯•**:
```bash
python retrieval/kg_expansion/entity_linking.py \
  --query "grammaire franÃ§aise" \
  --lang fr \
  --threshold 0.8
```

---

### 3. `retrieval/kg_expansion/hop_expand.py` (380è¡Œ)
**åŠŸèƒ½**: N-hopå›¾è°±æ‰©å±•å™¨

**æ ¸å¿ƒç±»**:
- `HopExpander`: N-hopæ‰©å±•ä¸»ç±»

**å…³é”®æ–¹æ³•**:
- `expand_from_nodes(node_ids, hops, relation_types)`: BFSå¹¿åº¦ä¼˜å…ˆæ‰©å±•
- `_get_node(session, node_id)`: è·å–èŠ‚ç‚¹ä¿¡æ¯
- `_get_neighbors(session, node_id, relation_types, limit)`: è·å–é‚»å±…èŠ‚ç‚¹
- `expand_with_constraints(node_ids, target_types, min_weight)`: å¸¦çº¦æŸæ‰©å±•
- `get_shortest_paths(start_ids, end_ids, max_length)`: æŸ¥æ‰¾æœ€çŸ­è·¯å¾„

**å…³é”®å‚æ•°**:
- `max_hops`: æœ€å¤§è·³æ•°(é»˜è®¤2,æ¥è‡ªconfig.KG_HOP_LIMIT)
- `max_neighbors`: æ¯èŠ‚ç‚¹æœ€å¤§é‚»å±…æ•°(é»˜è®¤20,æ¥è‡ªconfig.KG_MAX_NEIGHBORS)

**å…³é”®ç‰¹æ€§**:
- âœ… BFSé€å±‚æ‰©å±•(é¿å…æ·±åº¦ä¼˜å…ˆçš„é€’å½’çˆ†ç‚¸)
- âœ… å»é‡æœºåˆ¶(visitedé›†åˆé¿å…é‡å¤è®¿é—®)
- âœ… å…³ç³»è¿‡æ»¤(relation_typeså‚æ•°)
- âœ… é‚»å±…é™åˆ¶(é¿å…é«˜åº¦èŠ‚ç‚¹çˆ†ç‚¸)
- âœ… è·¯å¾„è®°å½•(è®°å½•æ‰€æœ‰æ‰©å±•è·¯å¾„)
- âœ… çº¦æŸæ‰©å±•(èŠ‚ç‚¹ç±»å‹ã€è¾¹æƒé‡è¿‡æ»¤)
- âœ… æœ€çŸ­è·¯å¾„(Cypher shortestPathç®—æ³•)

**è¿”å›æ ¼å¼**:
```json
{
  "nodes": [{"id": "...", "name": "...", "type": "...", "lang": "..."}],
  "edges": [{"source": "...", "target": "...", "relation": "...", "weight": ..., "hop": ...}],
  "paths": [{"start": "...", "end": "...", "length": ..., "nodes": [...], "relations": [...]}]
}
```

**CLIæµ‹è¯•**:
```bash
python retrieval/kg_expansion/hop_expand.py \
  --nodes concept1 concept2 \
  --hops 2 \
  --relations PREREQUISITE RELATED_TO \
  --output /tmp/expansion.json
```

---

### 4. `retrieval/kg_expansion/kg_path_score.py` (280è¡Œ)
**åŠŸèƒ½**: çŸ¥è¯†å›¾è°±è·¯å¾„è¯„åˆ†å™¨

**æ ¸å¿ƒç±»**:
- `KGPathScorer`: è·¯å¾„è¯„åˆ†ä¸»ç±»

**å…³é”®æ–¹æ³•**:
- `score_path(path, method)`: å•æ¡è·¯å¾„è¯„åˆ†(4ç§æ–¹æ³•)
- `_score_by_depth(path)`: æ·±åº¦è¯„åˆ†(exp(-depth_penalty * length))
- `_score_by_weight(path)`: è¾¹æƒé‡è¯„åˆ†(å¹³å‡æƒé‡)
- `_score_by_relation(path)`: å…³ç³»ç±»å‹è¯„åˆ†(ç±»å‹æƒé‡æ˜ å°„)
- `_score_combined(path)`: ç»„åˆè¯„åˆ†(æ·±åº¦ Ã— (æƒé‡ + å…³ç³»))
- `score_paths(paths, method)`: æ‰¹é‡è¯„åˆ†å¹¶æ’åº
- `score_nodes_from_paths(paths, aggregation)`: èŠ‚ç‚¹å¾—åˆ†èšåˆ(max/avg/sum)
- `rerank_documents(documents, kg_node_scores, alpha)`: æ–‡æ¡£é‡æ’åº
- `explain_score(path)`: è§£é‡Šè¯„åˆ†

**è¯„åˆ†å…¬å¼**:
```python
# æ·±åº¦è¯„åˆ† (è¶ŠçŸ­è¶Šå¥½)
depth_score = exp(-depth_penalty * length)

# ç»„åˆè¯„åˆ†
combined = depth_score * (
    weight_importance * avg_weight + 
    (1 - weight_importance) * avg_relation_score
)

# æ–‡æ¡£é‡æ’
final_score = alpha * kg_score + (1 - alpha) * original_score
```

**å…³é”®å‚æ•°**:
- `depth_penalty`: æ·±åº¦æƒ©ç½šç³»æ•°(é»˜è®¤0.5)
- `weight_importance`: è¾¹æƒé‡é‡è¦æ€§(é»˜è®¤0.8)
- `relation_weights`: å…³ç³»ç±»å‹æƒé‡å­—å…¸(PREREQUISITE=1.0æœ€é«˜)

**å…³é”®ç‰¹æ€§**:
- âœ… å¤šç§è¯„åˆ†ç­–ç•¥(depth/weight/relation/combined)
- âœ… æ·±åº¦æƒ©ç½š(æŒ‡æ•°è¡°å‡,é¿å…è¿‡é•¿è·¯å¾„)
- âœ… å…³ç³»æƒé‡(PREREQUISITE > RELATED_TO > PART_OF > IS_A)
- âœ… èŠ‚ç‚¹èšåˆ(max/avg/sumä¸‰ç§æ–¹å¼)
- âœ… æ–‡æ¡£é‡æ’(KGå¾—åˆ†ä¸åŸå§‹å¾—åˆ†èåˆ)
- âœ… å¯è§£é‡Šæ€§(explain_scoreè¾“å‡ºè¯¦ç»†åˆ†è§£)

**æµ‹è¯•**:
```python
python retrieval/kg_expansion/kg_path_score.py
# è¾“å‡ºæ¨¡æ‹Ÿè·¯å¾„çš„è¯„åˆ†ç»“æœå’Œè§£é‡Š
```

---

## âœ… éªŒè¯æ¸…å•

### 1. åŠŸèƒ½å®Œæ•´æ€§
- [x] Neo4jè¿æ¥ç®¡ç†(è¿æ¥ã€éªŒè¯ã€å…³é—­)
- [x] å›¾è°±å¯¼å…¥(æ¦‚å¿µã€å…³ç³»ã€æ‰¹é‡ã€å¢é‡)
- [x] å®ä½“é“¾æ¥(ç²¾ç¡®ã€æ¨¡ç³Šã€ç›¸ä¼¼åº¦)
- [x] N-hopæ‰©å±•(BFSã€å»é‡ã€è·¯å¾„è®°å½•)
- [x] è·¯å¾„è¯„åˆ†(4ç§ç­–ç•¥ã€èŠ‚ç‚¹èšåˆã€æ–‡æ¡£é‡æ’)
- [x] çº¦æŸç®¡ç†(å”¯ä¸€æ€§ã€ç´¢å¼•)
- [x] ç»Ÿè®¡åˆ†æ(èŠ‚ç‚¹/å…³ç³»/è¯­è¨€)

### 2. ç®—æ³•æ­£ç¡®æ€§
- [x] å®ä½“é“¾æ¥ä¸¤çº§åŒ¹é…(ç²¾ç¡®â†’æ¨¡ç³Š)
- [x] BFSæ‰©å±•(é€å±‚ã€å»é‡ã€é‚»å±…é™åˆ¶)
- [x] è·¯å¾„è¯„åˆ†å…¬å¼(æ·±åº¦æƒ©ç½šã€æƒé‡èåˆ)
- [x] Jaccardç›¸ä¼¼åº¦(å­—ç¬¦é›†åˆäº¤å¹¶æ¯”)
- [x] æœ€çŸ­è·¯å¾„(Cypher shortestPath)
- [x] æ–‡æ¡£é‡æ’(alphaèåˆ)

### 3. å·¥ç¨‹è´¨é‡
- [x] æ¨¡å—åŒ–è®¾è®¡(4ä¸ªç‹¬ç«‹æ¨¡å—)
- [x] é”™è¯¯å¤„ç†(è¿æ¥å¤±è´¥ã€æŸ¥è¯¢å¤±è´¥)
- [x] æ—¥å¿—è¾“å‡º(info/warning/error)
- [x] é…ç½®é›†æˆ(config.NEO4J_*, KG_HOP_LIMIT)
- [x] ç±»å‹æ³¨è§£(å…³é”®å‡½æ•°æœ‰ç±»å‹æç¤º)
- [x] ä¸Šä¸‹æ–‡ç®¡ç†å™¨(è‡ªåŠ¨èµ„æºæ¸…ç†)
- [x] CLIæ¥å£(4ä¸ªè„šæœ¬å‡å¯ç‹¬ç«‹æµ‹è¯•)

### 4. è®ºæ–‡å¯¹åº”æ€§
- [x] å®ä½“é“¾æ¥(å¯¹åº”è®ºæ–‡4.3.1èŠ‚)
- [x] å›¾è°±æ‰©å±•(å¯¹åº”è®ºæ–‡4.3.2èŠ‚)
- [x] è·¯å¾„è¯„åˆ†(å¯¹åº”è®ºæ–‡4.3.3èŠ‚)
- [x] æ·±åº¦æƒ©ç½š(è®ºæ–‡å…¬å¼: exp(-Î»Â·d))
- [x] å…³ç³»æƒé‡(è®ºæ–‡è¡¨æ ¼:å…³ç³»é‡è¦æ€§)

---

## ğŸ”¬ æµ‹è¯•åœºæ™¯

### åœºæ™¯1: Neo4jå¯¼å…¥æµ‹è¯•
```bash
# å‰ç½®:å¯åŠ¨Neo4jå®¹å™¨
docker-compose up -d

# 1. å‡†å¤‡Mockå›¾è°±æ•°æ®
mkdir -p data/kg
cat > data/kg/concepts.jsonl << 'EOF'
{"id": "fr_grammar", "name": "grammaire", "type": "CONCEPT", "lang": "fr", "description": "French grammar"}
{"id": "zh_grammar", "name": "è¯­æ³•", "type": "CONCEPT", "lang": "zh", "description": "Chinese grammar"}
{"id": "fr_verb", "name": "verbe", "type": "CONCEPT", "lang": "fr", "description": "French verb"}
EOF

cat > data/kg/relations.jsonl << 'EOF'
{"source": "fr_grammar", "target": "fr_verb", "type": "PREREQUISITE", "weight": 1.0, "confidence": 0.9}
{"source": "fr_grammar", "target": "zh_grammar", "type": "EQUIVALENT", "weight": 0.9, "confidence": 0.85}
EOF

# 2. å¯¼å…¥å›¾è°±
python kg/neo4j_import/import_to_neo4j.py \
  --concepts data/kg/concepts.jsonl \
  --relations data/kg/relations.jsonl \
  --clear \
  --test "grammaire"

# é¢„æœŸè¾“å‡º:
# - æ¦‚å¿µæ•°: 3
# - å…³ç³»æ•°: 2
# - å…³ç³»ç±»å‹: {'PREREQUISITE': 1, 'EQUIVALENT': 1}
# - grammaire --[PREREQUISITE]-> verbe
# - grammaire --[EQUIVALENT]-> è¯­æ³•
```

### åœºæ™¯2: å®ä½“é“¾æ¥æµ‹è¯•
```bash
# æ³•è¯­æŸ¥è¯¢é“¾æ¥åˆ°æ³•è¯­æ¦‚å¿µ
python retrieval/kg_expansion/entity_linking.py \
  --query "grammaire verbe" \
  --lang fr \
  --threshold 0.8

# é¢„æœŸ:
# - "grammaire" -> fr_grammar (confidence=1.0, ç²¾ç¡®åŒ¹é…)
# - "verbe" -> fr_verb (confidence=1.0, ç²¾ç¡®åŒ¹é…)

# è·¨è¯­è¨€é“¾æ¥(æ— NERæ—¶ä¾èµ–æ¨¡ç³ŠåŒ¹é…)
python retrieval/kg_expansion/entity_linking.py \
  --query "grammar" \
  --threshold 0.6

# é¢„æœŸ:
# - "grammar" -> fr_grammar (confidence=0.7+, æ¨¡ç³ŠåŒ¹é…)
```

### åœºæ™¯3: N-hopæ‰©å±•æµ‹è¯•
```bash
# ä»"grammaire"æ‰©å±•2-hop
python retrieval/kg_expansion/hop_expand.py \
  --nodes fr_grammar \
  --hops 2 \
  --output /tmp/kg_expansion.json

# é¢„æœŸç»“æœ(JSON):
# {
#   "nodes": [
#     {"id": "fr_grammar", "name": "grammaire", ...},
#     {"id": "fr_verb", "name": "verbe", ...},  # 1-hop
#     {"id": "zh_grammar", "name": "è¯­æ³•", ...}   # 1-hop
#   ],
#   "edges": [
#     {"source": "fr_grammar", "target": "fr_verb", "relation": "PREREQUISITE", "hop": 1},
#     {"source": "fr_grammar", "target": "zh_grammar", "relation": "EQUIVALENT", "hop": 1}
#   ],
#   "paths": [...]
# }

# æŸ¥çœ‹ç»“æœ
cat /tmp/kg_expansion.json | jq '.nodes | length'  # èŠ‚ç‚¹æ•°
cat /tmp/kg_expansion.json | jq '.edges | length'  # è¾¹æ•°
```

### åœºæ™¯4: è·¯å¾„è¯„åˆ†æµ‹è¯•
```bash
# è¿è¡Œå†…ç½®æµ‹è¯•
python retrieval/kg_expansion/kg_path_score.py

# é¢„æœŸè¾“å‡º:
# Path 1: Length=1, Relations=['RELATED_TO'], Score=0.85+
# Path 2: Length=2, Relations=['PREREQUISITE', 'RELATED_TO'], Score=0.75+
# Path 3: Length=3, Relations=['IS_A', 'PART_OF', 'RELATED_TO'], Score=0.60+
# (çŸ­è·¯å¾„ã€é«˜æƒé‡å…³ç³»å¾—åˆ†æ›´é«˜)
```

### åœºæ™¯5: ç«¯åˆ°ç«¯KGå¢å¼ºæµç¨‹
```python
# Pythonè„šæœ¬æµ‹è¯•å®Œæ•´æµç¨‹
from retrieval.kg_expansion import EntityLinker, HopExpander, KGPathScorer

# 1. å®ä½“é“¾æ¥
linker = EntityLinker()
query_entities = [{"entity": "grammaire", "type": "CONCEPT"}]
linked = linker.link_entities(query_entities, lang="fr")
print(f"é“¾æ¥ç»“æœ: {linked}")

# 2. å›¾è°±æ‰©å±•
expander = HopExpander()
node_ids = [item["kg_id"] for item in linked]
expansion = expander.expand_from_nodes(node_ids, hops=2)
print(f"æ‰©å±•èŠ‚ç‚¹: {len(expansion['nodes'])}")
print(f"æ‰©å±•è·¯å¾„: {len(expansion['paths'])}")

# 3. è·¯å¾„è¯„åˆ†
scorer = KGPathScorer()
scored_paths = scorer.score_paths(expansion["paths"], method="combined")
print(f"Top-3è·¯å¾„: {scored_paths[:3]}")

# 4. èŠ‚ç‚¹èšåˆ
node_scores = scorer.score_nodes_from_paths(scored_paths, aggregation="max")
print(f"èŠ‚ç‚¹å¾—åˆ†: {node_scores}")

# 5. æ–‡æ¡£é‡æ’(æ¨¡æ‹Ÿ)
documents = [
    {"doc_id": "doc1", "score": 0.8, "concepts": ["fr_verb"]},
    {"doc_id": "doc2", "score": 0.7, "concepts": ["fr_grammar"]}
]
reranked = scorer.rerank_documents(documents, node_scores, alpha=0.3)
print(f"é‡æ’å: {reranked}")

# æ¸…ç†
linker.close()
expander.close()
```

---

## ğŸ“Š æ€§èƒ½é¢„æœŸ

### Neo4jå¯¼å…¥
- **300èŠ‚ç‚¹ + 500è¾¹**: <10ç§’
- **3,000èŠ‚ç‚¹ + 5,000è¾¹**: <1åˆ†é’Ÿ
- **30,000èŠ‚ç‚¹ + 50,000è¾¹**: <5åˆ†é’Ÿ

### å®ä½“é“¾æ¥
- **å•æ¬¡æŸ¥è¯¢(3-5ä¸ªå®ä½“)**: <100ms
- **æ‰¹é‡100æŸ¥è¯¢**: <5ç§’

### N-hopæ‰©å±•
- **2-hopæ‰©å±•(èµ·å§‹èŠ‚ç‚¹åº¦æ•°<50)**: <200ms
- **3-hopæ‰©å±•**: <1ç§’
- **é«˜åº¦èŠ‚ç‚¹(åº¦æ•°>100)**: éœ€max_neighborsé™åˆ¶

### è·¯å¾„è¯„åˆ†
- **1000æ¡è·¯å¾„è¯„åˆ†**: <50ms
- **èŠ‚ç‚¹èšåˆ**: <10ms

---

## ğŸ”— æ¨¡å—é›†æˆå…³ç³»

```
æŸ¥è¯¢æ–‡æœ¬
    â†“
EntityLinker (å®ä½“é“¾æ¥)
    â†“ {kg_id: "...", confidence: ...}
HopExpander (N-hopæ‰©å±•)
    â†“ {nodes: [...], edges: [...], paths: [...]}
KGPathScorer (è·¯å¾„è¯„åˆ†)
    â†“ {node_scores: {node_id: score}}
æ–‡æ¡£é‡æ’ (ä¸Dense/Sparseèåˆ)
    â†“
æœ€ç»ˆæ’åºç»“æœ
```

### ä¸å…¶ä»–æ¨¡å—é›†æˆ

#### 1. ä¸NERé›†æˆ
```python
from kg.extraction.ner_fr import FrenchNER
from retrieval.kg_expansion import EntityLinker

ner = FrenchNER()
linker = EntityLinker()

query = "La grammaire franÃ§aise comprend les verbes"
entities = ner.extract_entities(query)  # NERè¯†åˆ«
linked = linker.link_entities(entities, lang="fr")  # é“¾æ¥åˆ°KG
```

#### 2. ä¸Dense/Sparseæ£€ç´¢èåˆ
```python
from retrieval.dense.dense_search import DenseSearcher
from retrieval.sparse.sparse_search import SparseSearcher
from retrieval.kg_expansion import EntityLinker, HopExpander, KGPathScorer

# ä¸‰è·¯æ£€ç´¢
dense_results = dense_searcher.search(query, top_k=100)
sparse_results = sparse_searcher.search(query, top_k=100)

# KGå¢å¼º
linker = EntityLinker()
expander = HopExpander()
scorer = KGPathScorer()

linked = linker.link_query(query, lang="fr")
node_ids = [item["kg_id"] for item in linked]
expansion = expander.expand_from_nodes(node_ids, hops=2)
scored_paths = scorer.score_paths(expansion["paths"])
kg_scores = scorer.score_nodes_from_paths(scored_paths)

# èåˆå¾—åˆ†(ä¸‹ä¸€æ­¥å®ç°fusion_rerank.py)
# final_score = Î±Â·dense + Î²Â·sparse + Î³Â·kg
```

---

## ğŸ¯ å®Œæˆæ ‡å‡†

### âœ… ä»£ç è´¨é‡
- [x] ç±»å‹æ³¨è§£(å…³é”®å‡½æ•°æœ‰ç±»å‹æç¤º)
- [x] é”™è¯¯å¤„ç†(è¿æ¥å¤±è´¥ã€æŸ¥è¯¢å¤±è´¥ã€æ•°æ®è§£æ)
- [x] æ—¥å¿—è¾“å‡º(info/warning/error)
- [x] æ–‡æ¡£å­—ç¬¦ä¸²(ç±»ã€å‡½æ•°ã€å‚æ•°ã€è¿”å›å€¼)
- [x] ä¸Šä¸‹æ–‡ç®¡ç†å™¨(Neo4jè¿æ¥è‡ªåŠ¨å…³é—­)

### âœ… åŠŸèƒ½å®Œæ•´
- [x] å›¾è°±å¯¼å…¥(æ‰¹é‡ã€å¢é‡ã€çº¦æŸ)
- [x] å®ä½“é“¾æ¥(ç²¾ç¡®ã€æ¨¡ç³Šã€ç›¸ä¼¼åº¦)
- [x] å›¾è°±æ‰©å±•(BFSã€å»é‡ã€è·¯å¾„)
- [x] è·¯å¾„è¯„åˆ†(4ç§ç­–ç•¥ã€èšåˆã€é‡æ’)
- [x] ç»Ÿè®¡åˆ†æ(èŠ‚ç‚¹/å…³ç³»/è¯­è¨€)

### âœ… å¯è¿è¡Œæ€§
- [x] ç‹¬ç«‹è¿è¡Œ(4ä¸ªæ¨¡å—å‡å¯ç‹¬ç«‹æµ‹è¯•)
- [x] CLIæ¥å£(argparseå®Œæ•´)
- [x] é…ç½®é›†æˆ(config.NEO4J_*, KG_*)
- [x] Dockerå…¼å®¹(docker-compose.ymlå·²æœ‰Neo4j)

### âœ… è®ºæ–‡å¯¹åº”
- [x] å®ä½“é“¾æ¥ç®—æ³•(è®ºæ–‡4.3.1)
- [x] N-hopæ‰©å±•ç®—æ³•(è®ºæ–‡4.3.2)
- [x] è·¯å¾„è¯„åˆ†å…¬å¼(è®ºæ–‡4.3.3)
- [x] æ·±åº¦æƒ©ç½š(exp(-Î»Â·d))
- [x] å…³ç³»æƒé‡(PREREQUISITEæœ€é«˜)

---

## ğŸ“ ä¸‹ä¸€æ­¥å»ºè®®

### å»ºè®®1: æµ‹è¯•KGå¢å¼ºæµç¨‹
```bash
# å®Œæ•´æµ‹è¯•æµç¨‹
cd /Users/robin/project/ai-tech-france

# 1. å¯åŠ¨Neo4j
docker-compose up -d

# 2. å‡†å¤‡Mockå›¾è°±æ•°æ®(è§åœºæ™¯1)
# ...

# 3. å¯¼å…¥å›¾è°±
python kg/neo4j_import/import_to_neo4j.py --concepts ... --relations ...

# 4. æµ‹è¯•å®ä½“é“¾æ¥
python retrieval/kg_expansion/entity_linking.py --query "grammaire" --lang fr

# 5. æµ‹è¯•æ‰©å±•
python retrieval/kg_expansion/hop_expand.py --nodes fr_grammar --hops 2

# 6. æµ‹è¯•è¯„åˆ†
python retrieval/kg_expansion/kg_path_score.py
```

### å»ºè®®2: ç»§ç»­Phase 1(èåˆæ’åº)
```
"è¯·å®ç° retrieval/rerank/fusion_rerank.py - èåˆDense+Sparse+KGç»“æœ"
```

### å»ºè®®3: æˆ–è€…è·³åˆ°Phase 3(è¯„æµ‹ç³»ç»Ÿ)
```
"è¯·å®ç°è¯„æµ‹ç³»ç»Ÿçš„5ä¸ªæ–‡ä»¶(metrics.py, run_eval.pyç­‰)"
```

### å»ºè®®4: æ„å»ºå®Œæ•´å›¾è°±
```
"è¯·å®ç° kg/neo4j_import/build_nodes_rels.py - ä»NER/å…³ç³»æŠ½å–ç»“æœæ„å»ºå›¾è°±"
```

---

## ğŸ‰ é‡Œç¨‹ç¢‘

âœ… **Phase 2 KGå¢å¼ºæ£€ç´¢: 100%å®Œæˆ**
- Neo4jå¯¼å…¥: 100% âœ…
- å®ä½“é“¾æ¥: 100% âœ…
- N-hopæ‰©å±•: 100% âœ…
- è·¯å¾„è¯„åˆ†: 100% âœ…

âœ… **MVPæ ¸å¿ƒè¿›åº¦: 55% â†’ 70%** â¬†ï¸â¬†ï¸

**è®ºæ–‡æ ¸å¿ƒåˆ›æ–°ç‚¹å·²å®ç°** ğŸŠ

ä¸‹ä¸€ä¸ªé˜»å¡é¡¹: **é˜»å¡4 - èåˆæ’åº** (é¢„è®¡1-2å°æ—¶)

---

## ğŸ” å…³é”®äº®ç‚¹

1. **ä¸¤çº§å®ä½“é“¾æ¥**: ç²¾ç¡®ä¼˜å…ˆâ†’æ¨¡ç³Šè¡¥å……,ä¿è¯å¬å›ç‡å’Œå‡†ç¡®ç‡
2. **BFSæ‰©å±•ç®—æ³•**: é€å±‚æ‰©å±•+å»é‡,é¿å…é€’å½’çˆ†ç‚¸
3. **æ·±åº¦æƒ©ç½šæœºåˆ¶**: æŒ‡æ•°è¡°å‡,ç¬¦åˆè®ºæ–‡å…¬å¼exp(-Î»Â·d)
4. **å¤šç­–ç•¥è¯„åˆ†**: depth/weight/relation/combinedå››ç§,çµæ´»å¯é…
5. **å…³ç³»æƒé‡æ˜ å°„**: PREREQUISITEæœ€é«˜,ç¬¦åˆæ•™è‚²åœºæ™¯è¯­ä¹‰
6. **æ‰¹é‡ä¼˜åŒ–**: æ‰€æœ‰å¯¼å…¥/æŸ¥è¯¢å‡æ”¯æŒæ‰¹å¤„ç†,æ€§èƒ½ä¼˜åŒ–
7. **å®Œæ•´CLI**: 4ä¸ªæ¨¡å—å‡å¯ç‹¬ç«‹æµ‹è¯•,å·¥ç¨‹åŒ–å®Œå–„

**è¿™æ˜¯è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®ç‚¹,å®ç°è´¨é‡ç›´æ¥å½±å“è®ºæ–‡æ¥æ”¶ç‡!** âœ¨
